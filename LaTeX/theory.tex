% !TEX root = ./main.tex
\documentclass[main.tex]{subfiles}
\begin{document}

\subsection{What Is a Prime?}
Prime numbers are defined as \textit{positive integers} which only have the
factors 1 and itself. Thus $4$ is not a prime since $4 = 2 * 2$. On the other
hand $5$ is a prime since the only divisors of $5$ is $1$ and $5$. If the
number, $n$, is not prime, it is referred to as a \textit{composite number}. \\

An exception to this definition is $1$, since it is the first natural number.
Subsection (\ref{arithmetic}) provides a more in-depth definition of prime
numbers, and a mathematical explanation about why $1$ is not a prime number.

\subsection{Mersenne Primes}
A mersenne prime is a prime that can be written as $2^{p}-1$ where $p$ is also a
prime number. An example of this is $2^5-1$ which equals to the prime number
$127$. The eight largest prime numbers are mersenne primes
\cite{prime:largest_digits}. The reason being because of their easily
exploitable properties by computers, making them faster to test for primality
than normal integers.

\subsection{The Fundamental Theory of Arithmetic} \label{arithmetic} The
Fundamental Theory of Arithmetic \cite{theorem:arithmetic} states that all
integers greater than $1$ is either a prime, or can be expressed as a product of
primes in a unique way. This means that all natural numbers, except for $1$, has
its own factorisation containing only primes, unless it is a prime itself.
\newline
\\*
This study relies on the fact that there is an infinite amount of primes. The
proof for this is a simple proof by contradiction: \\

\begin{mdframed}
  \begin{center}
    Assume that there is a finite amount of primes and make a list of them:
  \end{center}

  \begin{center}
    $p_1, p_2, p_3, p_4, p_5, ...$
  \end{center}
  \newline

  \begin{center}
    Let the constant $Q$ be the product of all the primes in the list plus $1$:
  \end{center}

  \begin{center}
    $Q = p_1 * p_2 * p_3 * ... + 1$
  \end{center}
  \newline

  \centering
  According to the fundamental theorem of arithmetic, $Q$ must be a prime since
  none of the primes in the list divide $Q$ evenly because of the $1$; therefore
  making the list incomplete and proving that you cannot make a finite list of
  all primes.
\end{mdframed}
\vspace{5mm}

\subsection{The Prime Number Theorem}
The Prime Number Theorem \cite{theorem:prime_num} describes approximately how
many primes there are less than or equal to a given number. The function $\pi(N)
\sim \frac{N}{\ln(N)}$ gives the expected amount of primes below a certain $N$.
Graphing this function shows that primes become less common for greater $N$. \\

\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[ axis lines = left, xlabel = $N$, ylabel = {}, ]
        \addplot [ domain=0:100000, samples=100, color=red, ]{x/ln(x)};
        \addlegendentry{$\frac{N}{ln(N)}$}
            
        \addplot [ domain=0:100000, samples=100, color=blue, ]{x};
        \addlegendentry{$N$}
      \end{axis}
    \end{tikzpicture}
  \end{center}
  \caption{The graph of $\pi(N)$ and $N$ from $0$ to $10^{5}$ can be used to
    compare the relationship between the number $N$ and the approximate amount
    of primes below it.}
\end{figure}

Worth to note is that $\pi(N)$ looks linear in this graph. The function is not
actually linear, but because of the graph's large domain, the functions seems
like it is linear.

This shows that primes do not show up linearly, meaning a computer that is
twice as powerful will \textit{not} produce twice as many primes. Instead, the
largest factor for verifying primes faster is the \textit{algorithms}.

\subsection{Time Complexity}

Time complexity \cite{theorem:time_comp} is a concept within computer science,
which describes the approximate time for a program to complete. The study will
use of the Big O Notation \cite{theorem:big_O}, which notates how the run time
increases as the input size increases. For example, $\mathcal{O}(N)$ will grow
linearly with the input size. Increasing the input size by a factor of 10, will
also increase the run time by a factor of 10, as such $\mathcal{O}(10N)$. On the
other hand, $\mathcal{O}(\log(N))$ grows logarithmically, which is far more
efficient for bigger input sizes, as $\mathcal{O}(\log(N))$ is strictly smaller
than $N$ for large enough values. The base for logarithms in the Big O Notation
is not relevant. The proof as to why the base is irrelevant will not be
provided. \newline
\\*
The amount of operations a modern computer can do is in the order of magnitude
of $10^{9}$ per second. An operation is, for example, adding two numbers or
storing a number in an array. \newline
\\*
Since the Big O Notation denotes the growth of the runtime as
$\lim_{N\to\infty}$, two notations can be added together rather easily. For
example, a program that has two bits of codes, one with $\mathcal{O}(N)$ and
another with $\mathcal{O}(N^{2})$, will have an overall time complexity of
$\mathcal{O}(N^{2})$ since $N^{2}$ dominates for large values of $N$.

\subsection{Deterministic vs. Probabilistic}
A deterministic test is a one-hundred percent definite test for primes, that
gives no false positives. It either returns true if the number being tested if
prime, or false if the number is not prime. \newline

Probabilistic tests differ from deterministic tests by having a stochastic,
random factor in them. They are not one-hundred percent definite and therefore
sometimes will give false positives/negatives. \\

An example of a probabilistic test for the number $p$ would be to test a random
number below $p$ and see if it divides $p$ evenly. This test would give a lot of
false positives, because even if $p$ were to be composite, not all numbers below
it will divide it. The accuracy of the test, i.e. the probability that it
returns a correct answer, is higher if there is an increased amount of unique
factors, $k$, tested.

\subsection{Algorithms}

\subsubsection{Brute-force} \label{brute} The brute force method is a
deterministic method that tests all the
integers, $n$, between $2$ and $p-1$ and checks if $n$ satisfies $n \equiv 0
\Mod{p}$. If the condition is satisfied, $n$ would be a divisor of $p$ which
would make $p$ not a prime. However, if the loop completes without finding any
divisors to $p$, then $p$ is prime. The brute force algorithm is a definite
test, since it follows the definition of a prime; $p$ is prime if and only if
there are no divisors except for 1 and $p$ itself. The algorithm's time
complexity is $\mathcal{O}(N)$, meaning it increases linearly. The code for this
algorithm is shown below. All code in this study will be written in Python. The
reason behind this will be discussed later.\newline

\lstinputlisting[language=python]{../Python/brute.py}

\subsubsection{Smart Brute-force}
The smart brute force is a variant of the brute force algorithm (\ref{brute}).
By utilising some properties of primes, the smart brute force has a time
complexity of $\mathcal{O}(\sqrt{N})$ compared to the $\mathcal{O}(N)$
complexity from the brute force. Just like the original brute-force, this
algorithm is deterministic aswell.\\

Since a prime can never have the factor $2$ in them, it is sufficient to only
test odd numbers. Assuming that $p$ is a composite, it must have at least 2
factors. Therefore, the smart brute force only tests numbers up to $\sqrt{p}$,
since if a factor larger than $\sqrt{p}$ were to be found, the others must have
already been tested. \newline

\lstinputlisting[language=python]{../Python/smartbrute.py}

\subsubsection{Lucas-Lehmer}
The Lucas-Lehmer algorithm \cite{algh:lucas} is a deterministic primality test
that only works for Mersenne numbers. It takes advantage of the special
properties of mersenne numbers: \newline

\begin{mdframed}
  \begin{center}
    For some $p>2$, $M_p=2^p-1$ is prime if $M_p$ divides $S_{p-2}$ where $S_0=4$ and
    $S_k=(S_{k-1})^2-2$ for $k>0$.
  \end{center}
\end{mdframed}

The Lucas-Lehmer test has helped the GIMPS (Great Internet Mersenne Prime
Search) \cite{GIMPS} to find many of the largest primes known. This is because
the time complexity of the algorithm is much faster compared to the other
algorithms. The time complexity being $\mathcal{O}(\log^{2}(N) \log \log N)$. \\

\lstinputlisting[language=python]{../Python/lucas.py}

\subsubsection{Fermat} \label{fermat} The Fermat primality test
\cite{algh:fermat} is a probabilistic algorithm. Its whole concept is based on
Fermat's little theory \cite{fermat:little} which states:

\begin{mdframed}
  \begin{center}
    If $p$ is prime and $a$ is not divisible by $p$ then: \\
    $a^{p - 1} \equiv 1 \Mod{p}$
  \end{center}
\end{mdframed}

To implement the Fermat test, the code randomises an integer for $a$ and checks
if it agrees with the theory. If it does not, then $p$ cannot be prime. However
if it does, then it is \emph{probably} prime. The accuracy of the test is higher
if it tries more than one $a$. In the code the amount of \emph{rounds} is
determined with the variable $k$. The time complexity for the algorithm is
$\mathcal{O}(k \log^{2}N \log \log N \log \log \log N)$. The speed of the test
can be compared to Lucas-Lehmer.  \\

\lstinputlisting[language=python]{../Python/fermat.py}

\subsubsection{Millerâ€“Rabin} The Miller-Rabin primality test \cite{algh:miller},
first discovered by Russian mathematician M. M. Artjuhov in 1967, is based on
the Fermat test (\ref{fermat}) and has two variants. One that is deterministic, and the other probabilistic. \\

The deterministic version is conditional, meaning that it relies on an unproven
theorem, in this case, the extended Riemann hypothesis \cite{riemann}. On the
other hand, the probabilistic version is unconditional, meaning that it does not
depend on an unproven theorem. This makes the probabilistic version a more
reliable primality test. If the extended Riemann hypothesis were to be
disproved, the deterministic version would fall apart. The probabilistic variant
is also faster for bigger $n$ compared to the deterministic version. For these
reasons, the probabilistic version is chosen for this study. \newline

The time complexity for the probabilistic version is $\mathcal{O}(k
\log^{3}(N))$, where $k$ is the amount of rounds the algorithm will perform. \\

\lstinputlisting[language=python]{../Python/milrab.py}

\end{document}
